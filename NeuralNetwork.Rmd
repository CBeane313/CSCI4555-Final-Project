
```{r,echo=FALSE, message=FALSE}
#Load packages
library(readr)
library(knitr)
library(dplyr)
library(stringr)
library(keras)
library(Metrics)
```

# Steam Game Data Neural Network Project

___ 

##### Table of Contents  
1. [Data Preperation](#dataprep)
    a. [Load Data](#dataload)
    b. [Data Preproccessing](#dataprepro)
2. [Data Splitting](#datasplit)
4. [Linear Model for Comparison](#lmmodel)
5. [Neural Network Model Attempt 1](#NNmod)
6. [Neural Network Model Attempt 2](#NNmod2)
6. [Neural Network Model Attempt 3](#NNmod3)
    
___

<a name="dataprep"></a>

## Data Preparation

<a name="dataload"></a>

### Load Data
```{r,warning = FALSE}
steamdata <- read_csv("steamGameData.csv", na = c("nan"))
```

<a name="dataprepro"></a>

### Data Preprocessing
```{r}
#Rename id column(it was missing one, and received default name)
colnames(steamdata)[which(colnames(steamdata) == "X1")] <- "id"
colnames(steamdata)[which(colnames(steamdata) == "24_hour_peak")] <- "twenty4_hr_peak"

#Drop NA observations 
steamdata <- na.omit(steamdata)


#Extract game engine from detected_technologies
steamdata$engine <- ifelse(str_detect(steamdata$detected_technologies, "Engine\\."), str_extract(steamdata$detected_technologies, "(?<=Engine\\.)(\\w+)"), NA)

#Drop NA observations 
steamdata <- na.omit(steamdata)

#now removes detected technologies
steamdata <- subset(steamdata, select = -c(detected_technologies))

#Remove (#) from primary genre
steamdata$primary_genre <- gsub("\\s*\\(\\d+\\)", "", steamdata$primary_genre)

#Make columns factors rather than strings
steamdata$engine <- as.factor(steamdata$engine)
steamdata$developer <- as.factor(steamdata$developer)
steamdata$primary_genre <- as.factor(steamdata$primary_genre)

#Make dates actual dates
steamdata$release <- as.Date(steamdata$release)

steamdata <- subset(steamdata, select = -c(id, game, link, store_genres, store_asset_mod_time, players_right_now, twenty4_hr_peak, all_time_peak_date, publisher, release, developer, peak_players))

#Converts genres and engines to numbers for one hot encoding
steamdata$primary_genre_number <- factor(steamdata$primary_genre)
steamdata$primary_genre_number <-as.numeric(steamdata$primary_genre_number)
steamdata$engine_number <- factor(steamdata$engine)
steamdata$engine_number <- as.numeric(steamdata$engine_number)
steamdata$engine_number <- to_categorical(as.numeric(steamdata$engine_number, num_classes =  83))
steamdata$primary_genre_number <- to_categorical(as.numeric(steamdata$primary_genre_number, num_classes = 24))


#Show head of data
head(steamdata)%>%kable()
```

<a name="datasplit"></a>

## Data Splitting

```{r}
## 75% of the sample size
smp_size <- floor(0.75 * nrow(steamdata))

## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(steamdata)), size = smp_size)

train <- steamdata[train_ind, ]
test <- steamdata[-train_ind, ]
```

<a name="lmmodel"></a>

## Linear Model For Comparison

```{r}
linearmod <- lm(rating ~ positive_reviews*negative_reviews*total_reviews*review_percentage+primary_genre+all_time_peak, data = steamdata)

# Get predicted values
predicted_values <- predict(linearmod, newdata = test)

# Calculate MAE
mae_value <- mae(test$rating, predicted_values)

sum<-summary(linearmod)
cat("R Squared =",sum$r.squared)
cat("MAE =",mae_value)
```

<a name="NNmod"></a>

## Neural Network Model Attempt 1

```{r}
set.seed(1234)

attempt1train <- subset(train, select = -c(primary_genre,primary_genre_number,all_time_peak,engine,engine_number,negative_reviews))
attempt1test <- subset(test, select = -c(primary_genre,primary_genre_number,all_time_peak,engine,engine_number,negative_reviews))

# Define R-squared for evaluation
r_squared <- custom_metric("r_squared", function(y_true, y_pred) {
  SS_res <- k_sum(k_square(y_true - y_pred))
  SS_tot <- k_sum(k_square(y_true - k_mean(y_true)))
  return(1 - SS_res /SS_tot)
})

model = keras_model_sequential() %>%
  layer_dense(units = 64, activation = "relu",input_shape=(3)) %>%
  layer_dense(units = 64, activation = "sigmoid") %>%
  layer_dense(units = 1, activation = "linear")

model %>% compile(
  loss = "mse",
  optimizer = "adam", 
  metrics = c("mean_absolute_error", r_squared)
)

trainx1 <- as.matrix(subset(attempt1train, select = -c(rating)))

model %>%
  fit(
    x = trainx1,
    y = attempt1train$rating,
    epochs = 17
  )

testx1 <- as.matrix(subset(attempt1test, select = -c(rating)))

# R Squared in the evaluation is not calculated properly
results <- model %>% evaluate(testx1, attempt1test$rating)
```


<a name="NNmod2"></a>

## Neural Network Model Attempt 2

```{r}
set.seed(1234)

attempt1train <- subset(train, select = -c(primary_genre,all_time_peak,engine,negative_reviews))
attempt1test <- subset(test, select = -c(primary_genre,all_time_peak,engine,negative_reviews))

# Define R-squared for evaluation
r_squared <- custom_metric("r_squared", function(y_true, y_pred) {
  SS_res <- k_sum(k_square(y_true - y_pred))
  SS_tot <- k_sum(k_square(y_true - k_mean(y_true)))
  return(1 - SS_res /SS_tot)
})

model = keras_model_sequential() %>%
  layer_dense(units = 256, activation = "relu",input_shape=(112)) %>%
  layer_dense(units = 64, activation = "sigmoid") %>%
  layer_dense(units = 1, activation = "linear")

model %>% compile(
  loss = "mse",
  optimizer = "adam", 
  metrics = c("mean_absolute_error", r_squared)
)

trainx1 <- as.matrix(subset(attempt1train, select = -c(rating)))

model %>%
  fit(
    x = trainx1,
    y = attempt1train$rating,
    epochs = 17
  )

testx1 <- as.matrix(subset(attempt1test, select = -c(rating)))

# R Squared in the evaluation is not calculated properly
results <- model %>% evaluate(testx1, attempt1test$rating)
```

<a name="NNmod3"></a>

## Neural Network Model Attempt 3

```{r}
set.seed(1234)

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

attempt1train <- subset(train, select = -c(primary_genre,all_time_peak,engine,negative_reviews))
attempt1test <- subset(test, select = -c(primary_genre,all_time_peak,engine,negative_reviews))

normtrain <- keras::normalize(attempt1train[,c(1:4)], order = 2 )
attempt1train[1]=normtrain[1]
attempt1train[2]=normtrain[2]
attempt1train[3]=normtrain[3]
attempt1train[4]=normtrain[4]

normtest <- keras::normalize(attempt1test[,c(1:4)], order = 2 )
attempt1test[1]=normtest[1]
attempt1test[2]=normtest[2]
attempt1test[3]=normtest[3]
attempt1test[4]=normtest[4]

# Define R-squared for evaluation
r_squared <- custom_metric("r_squared", function(y_true, y_pred) {
  SS_res <- k_sum(k_square(y_true - y_pred))
  SS_tot <- k_sum(k_square(y_true - k_mean(y_true)))
  return(1 - SS_res /SS_tot)
})

model = keras_model_sequential() %>%
  layer_dense(units = 256, activation = "relu",input_shape=(112)) %>%
  layer_dense(units = 64, activation = "sigmoid") %>%
  layer_dense(units = 1, activation = "linear")

model %>% compile(
  loss = "mse",
  optimizer = "adam", 
  metrics = c("mean_absolute_error", r_squared)
)

trainx1 <- as.matrix(subset(attempt1train, select = -c(rating)))

model %>%
  fit(
    x = trainx1,
    y = attempt1train$rating,
    epochs = 17
  )

testx1 <- as.matrix(subset(attempt1test, select = -c(rating)))

# R Squared in the evaluation is not calculated properly
results <- model %>% evaluate(testx1, attempt1test$rating)
```


